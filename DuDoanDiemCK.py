# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import StackingRegressor
from sklearn.metrics import r2_score
import json

try:
    # Äá»c file
    df = pd.read_csv("./data/annonimized.csv")
    df_gt = pd.read_csv("./data/ck-public.csv")
    print("âœ… ÄÃ£ Ä‘á»c dá»¯ liá»‡u")
    
    # Kiá»ƒm tra cáº¥u trÃºc dá»¯ liá»‡u
    print(f"Shape cá»§a df: {df.shape}")
    print(f"Columns cá»§a df: {df.columns.tolist()}")
    print(f"Shape cá»§a df_gt: {df_gt.shape}")
    print(f"Columns cá»§a df_gt: {df_gt.columns.tolist()}")
    
except Exception as e:
    print(f"âŒ Lá»—i Ä‘á»c dá»¯ liá»‡u: {e}")
    exit(1)

# Preprocess data   
# Äá»•i tÃªn cá»™t
df.columns = ["assignment_id", "problem_id", "username", "is_final", "status",
                "pre_score", "coefficient", "language_id", "created_at",
                "updated_at", "judgement"]

# Xá»­ lÃ½ datetime vá»›i error handling
try:
    df["created_at"] = pd.to_datetime("2025-" + df["created_at"].astype(str), 
                                    format="%Y-%m-%d %H:%M:%S", errors='coerce')
    df["updated_at"] = pd.to_datetime("2025-" + df["updated_at"].astype(str), 
                                    format="%Y-%m-%d %H:%M:%S", errors='coerce')
except Exception as e:
    print(f"âš ï¸ Lá»—i xá»­ lÃ½ datetime: {e}")
    # Thá»­ format khÃ¡c
    df["created_at"] = pd.to_datetime(df["created_at"], errors='coerce')
    df["updated_at"] = pd.to_datetime(df["updated_at"], errors='coerce')

# Kiá»ƒm tra missing values
print("\nMissing values in each column:")
print(df.isnull().sum())

# Xá»­ lÃ½ missing values vá»›i kiá»ƒm tra kiá»ƒu dá»¯ liá»‡u
if 'pre_score' in df.columns:
    df["pre_score"] = pd.to_numeric(df["pre_score"], errors='coerce')
    df["pre_score"] = df["pre_score"].fillna(0)
    
    # Kiá»ƒm tra outliers trong pre_score
    Q1 = df["pre_score"].quantile(0.25)
    Q3 = df["pre_score"].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    print(f"\nOutliers in pre_score: {len(df[(df['pre_score'] < lower_bound) | (df['pre_score'] > upper_bound)])}")

# Chuyá»ƒn Ä‘á»•i cÃ¡c cá»™t categorical
if 'status' in df.columns:
    df["status"] = df["status"].astype("category")
if 'language_id' in df.columns:
    df["language_id"] = df["language_id"].astype("category")

print("\nData types after preprocessing:")
print(df.dtypes)

# Extract features
def extract_verdicts(judgement_str):
    """
    TrÃ­ch xuáº¥t thÃ´ng tin verdict tá»« chuá»—i JSON
    """
    try:
        # Kiá»ƒm tra náº¿u lÃ  NaN hoáº·c None
        if pd.isna(judgement_str) or judgement_str is None:
            return {
                'num_verdicts': 0,
                'num_wrong': 0,
                'num_time_limit': 0,
                'num_memory_limit': 0,
                'num_runtime_error': 0,
                'error_ratio': 0
            }
        
        # Parse JSON string
        judgement = json.loads(str(judgement_str))
        
        # Khá»Ÿi táº¡o biáº¿n Ä‘áº¿m
        total_verdicts = 0
        wrong_count = 0
        time_limit_count = 0
        memory_limit_count = 0
        runtime_error_count = 0
        
        # Get verdicts from the correct structure
        if isinstance(judgement, dict) and 'verdicts' in judgement:
            verdicts = judgement['verdicts']
            if isinstance(verdicts, dict):
                # Äáº¿m tá»«ng loáº¡i verdict
                wrong_count = verdicts.get('WRONG', 0)
                time_limit_count = verdicts.get('Time Limit Exceeded', 0)
                memory_limit_count = verdicts.get('Memory Limit Exceeded', 0)
                runtime_error_count = verdicts.get('Runtime Error', 0)
                total_verdicts = sum(verdicts.values())
            elif isinstance(verdicts, list):
                # Náº¿u verdicts lÃ  list, Ä‘áº¿m tá»«ng loáº¡i
                for verdict in verdicts:
                    if verdict == 'WRONG':
                        wrong_count += 1
                    elif verdict == 'Time Limit Exceeded':
                        time_limit_count += 1
                    elif verdict == 'Memory Limit Exceeded':
                        memory_limit_count += 1
                    elif verdict == 'Runtime Error':
                        runtime_error_count += 1
                total_verdicts = len(verdicts)
        
        # TÃ­nh tá»‰ lá»‡ lá»—i
        error_ratio = (wrong_count + time_limit_count + memory_limit_count + runtime_error_count) / total_verdicts if total_verdicts > 0 else 0
        
        return {
            'num_verdicts': total_verdicts,
            'num_wrong': wrong_count,
            'num_time_limit': time_limit_count,
            'num_memory_limit': memory_limit_count,
            'num_runtime_error': runtime_error_count,
            'error_ratio': error_ratio
        }
        
    except json.JSONDecodeError as e:
        print(f"Lá»—i JSON: {e}")
        return {
            'num_verdicts': 0,
            'num_wrong': 0,
            'num_time_limit': 0,
            'num_memory_limit': 0,
            'num_runtime_error': 0,
            'error_ratio': 0
        }
    except Exception as e:
        print(f"Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}")
        return {
            'num_verdicts': 0,
            'num_wrong': 0,
            'num_time_limit': 0,
            'num_memory_limit': 0,
            'num_runtime_error': 0,
            'error_ratio': 0
        }

# Ãp dá»¥ng hÃ m extract_verdicts vÃ o cá»™t judgement
if 'judgement' in df.columns:
    print("Äang xá»­ lÃ½ judgement...")
    judgement_features = df['judgement'].apply(extract_verdicts)
    
    # Chuyá»ƒn Ä‘á»•i káº¿t quáº£ thÃ nh DataFrame
    judgement_df = pd.DataFrame(judgement_features.tolist())
    
    # XÃ³a cÃ¡c cá»™t cÅ© náº¿u Ä‘Ã£ tá»“n táº¡i
    columns_to_drop = ['num_verdicts', 'num_wrong', 'num_time_limit', 'num_memory_limit', 'num_runtime_error', 'error_ratio']
    df = df.drop(columns=columns_to_drop, errors='ignore')
    
    # Káº¿t há»£p vá»›i DataFrame gá»‘c
    df = pd.concat([df, judgement_df], axis=1)
    
    print("âœ… ÄÃ£ xá»­ lÃ½ xong judgement features")
    print(f"Shape sau khi thÃªm features: {df.shape}")
else:
    print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y cá»™t 'judgement'")
    # Táº¡o cÃ¡c cá»™t máº·c Ä‘á»‹nh
    df['num_verdicts'] = 0
    df['num_wrong'] = 0
    df['num_time_limit'] = 0
    df['num_memory_limit'] = 0
    df['num_runtime_error'] = 0
    df['error_ratio'] = 0
    
# Combine features
# Tá»•ng há»£p theo sinh viÃªn vá»›i error handling
try:
    print("Äang tá»•ng há»£p dá»¯ liá»‡u theo sinh viÃªn...")
    
    # Kiá»ƒm tra cÃ¡c cá»™t cáº§n thiáº¿t
    required_cols = ['username', 'assignment_id', 'pre_score', 'is_final']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"âŒ Thiáº¿u cÃ¡c cá»™t: {missing_cols}")
        exit(1)
    
    agg_dict = {
        'assignment_id': 'count',  # Sá»‘ lÆ°á»£ng bÃ i táº­p Ä‘Ã£ lÃ m
        'pre_score': ['mean', 'max'],  # Äiá»ƒm trung bÃ¬nh vÃ  cao nháº¥t
        'num_verdicts': 'mean',  # Sá»‘ láº§n ná»™p bÃ i trung bÃ¬nh
        'num_wrong': 'mean',  # Sá»‘ láº§n sai trung bÃ¬nh
        'num_time_limit': 'mean',  # Sá»‘ láº§n vÆ°á»£t thá»i gian trung bÃ¬nh
        'num_memory_limit': 'mean',  # Sá»‘ láº§n vÆ°á»£t bá»™ nhá»› trung bÃ¬nh
        'num_runtime_error': 'mean',  # Sá»‘ láº§n lá»—i runtime trung bÃ¬nh
        'error_ratio': 'mean',  # Tá»· lá»‡ lá»—i trung bÃ¬nh
        'is_final': 'sum'  # Sá»‘ lÆ°á»£ng bÃ i lÃ m Ä‘Ãºng
    }
    
    # ThÃªm created_at náº¿u cÃ³
    if 'created_at' in df.columns and not df['created_at'].isna().all():
        agg_dict['created_at'] = ['min', 'max']
    
    student_features = df.groupby("username").agg(agg_dict).reset_index()
    
    # Flatten column names
    new_columns = ['username']
    for col in student_features.columns[1:]:
        if isinstance(col, tuple):
            new_columns.append(f"{col[0]}_{col[1]}")
        else:
            new_columns.append(col)
    
    student_features.columns = new_columns
    
    # Äá»•i tÃªn cá»™t cho dá»… hiá»ƒu
    rename_dict = {
        'assignment_id_count': 'total_assignments',
        'pre_score_mean': 'avg_score',
        'pre_score_max': 'max_score',
        'num_verdicts_mean': 'avg_submissions',
        'num_wrong_mean': 'avg_wrong_attempts',
        'num_time_limit_mean': 'avg_time_limit_errors',
        'num_memory_limit_mean': 'avg_memory_limit_errors',
        'num_runtime_error_mean': 'avg_runtime_errors',
        'error_ratio_mean': 'avg_error_ratio',
        'is_final_sum': 'total_correct'
    }
    
    # ThÃªm datetime columns náº¿u cÃ³
    if 'created_at_min' in student_features.columns:
        rename_dict.update({
            'created_at_min': 'first_submission',
            'created_at_max': 'last_submission'
        })
    
    student_features = student_features.rename(columns=rename_dict)
    
    # Táº¡o cÃ¡c features bá»• sung
    student_features['correct_ratio'] = student_features['total_correct'] / student_features['total_assignments']
    
    # Xá»­ lÃ½ thá»i gian náº¿u cÃ³
    if 'first_submission' in student_features.columns and 'last_submission' in student_features.columns:
        student_features['total_days'] = (student_features['last_submission'] - student_features['first_submission']).dt.days
        student_features['total_days'] = student_features['total_days'].fillna(1)
        student_features['submission_rate'] = student_features['total_assignments'] / student_features['total_days'].replace(0, 1)
    
    print(f"âœ… Tá»•ng há»£p xong. Shape: {student_features.shape}")
    
except Exception as e:
    print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh tá»•ng há»£p: {e}")
    exit(1)

# Label ground truth
try:
    print("Äang gáº¯n nhÃ£n ground truth...")
    
    # Kiá»ƒm tra cáº¥u trÃºc df_gt
    if 'hash' not in df_gt.columns:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t 'hash' trong file ground truth")
        print(f"CÃ¡c cá»™t cÃ³ sáºµn: {df_gt.columns.tolist()}")
        exit(1)
    
    if 'CK' not in df_gt.columns:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t 'CK' trong file ground truth")
        print(f"CÃ¡c cá»™t cÃ³ sáºµn: {df_gt.columns.tolist()}")
        exit(1)
    
    student_features = student_features.merge(df_gt, how="left", left_on="username", right_on="hash")
    
    # PhÃ¢n chia dá»¯ liá»‡u
    unknown_students = set(df["username"]) - set(df_gt["hash"])
    test_data = student_features[student_features["username"].isin(unknown_students)]
    train_data = student_features[student_features["username"].isin(df_gt["hash"])]
    
    print(f"Sá»‘ sinh viÃªn training: {len(train_data)}")
    print(f"Sá»‘ sinh viÃªn testing: {len(test_data)}")
    
    if len(train_data) == 0:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u training!")
        exit(1)
    
    # Chuáº©n bá»‹ features cho training
    feature_columns = [col for col in student_features.columns 
                      if col not in ["username", "hash", "CK", "first_submission", "last_submission"]]
    
    X_train = train_data[feature_columns]
    y_train = pd.to_numeric(train_data["CK"], errors="coerce")
    
    # Loáº¡i bá» cÃ¡c giÃ¡ trá»‹ NaN
    valid_indices = ~(y_train.isna() | X_train.isna().any(axis=1))
    X_train = X_train[valid_indices]
    y_train = y_train[valid_indices]
    
    print(f"Sá»‘ máº«u training sau khi lÃ m sáº¡ch: {len(X_train)}")
    print(f"Sá»‘ features: {len(feature_columns)}")
    print(f"Features: {feature_columns}")
    
    if len(X_train) == 0:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u training há»£p lá»‡!")
        exit(1)
    
except Exception as e:
    print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh chuáº©n bá»‹ dá»¯ liá»‡u: {e}")
    exit(1)
# Chia train/validation split
try:
    print("Äang chia dá»¯ liá»‡u train/validation...")
    
    # Chia 90% train, 10% validation
    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
        X_train, y_train, 
        test_size=0.1, 
        random_state=42,
        stratify=None  # CÃ³ thá»ƒ thÃªm stratify náº¿u cáº§n
    )
    
    print(f"Táº­p training: {len(X_train_split)} samples")
    print(f"Táº­p validation: {len(X_val_split)} samples")
    
except Exception as e:
    print(f"âŒ Lá»—i khi chia dá»¯ liá»‡u: {e}")
    # Fallback: sá»­ dá»¥ng toÃ n bá»™ dá»¯ liá»‡u cho training
    X_train_split, X_val_split = X_train, None
    y_train_split, y_val_split = y_train, None
    
# Train model and predict
# Training model
try:
    print("Äang training model...")
    
    # Import vÃ  train LightGBM
    from lightgbm import LGBMRegressor
    from sklearn.metrics import mean_squared_error, mean_absolute_error
    
    model = LGBMRegressor(
        n_estimators=300, 
        learning_rate=0.05, 
        random_state=42,
        verbose=-1,  # Táº¯t log
        early_stopping_rounds=50 if X_val_split is not None else None
    )
    
    # Fit vá»›i validation set náº¿u cÃ³
    if X_val_split is not None:
        model.fit(
            X_train_split, y_train_split,
            eval_set=[(X_val_split, y_val_split)],
            eval_metric='rmse',
        )
    else:
        model.fit(X_train_split, y_train_split)
        
    print("âœ… Training hoÃ n thÃ nh")
    
# ÄÃ¡nh giÃ¡ trÃªn táº­p training
    train_preds = model.predict(X_train_split)
    train_r2 = r2_score(y_train_split, train_preds)
    train_rmse = np.sqrt(mean_squared_error(y_train_split, train_preds))
    train_mae = mean_absolute_error(y_train_split, train_preds)
    
    print(f"\nğŸ“Š Káº¿t quáº£ trÃªn táº­p TRAINING:")
    print(f"RÂ² score: {train_r2:.4f}")
    print(f"RMSE: {train_rmse:.4f}")
    print(f"MAE: {train_mae:.4f}")
    
    # ÄÃ¡nh giÃ¡ trÃªn táº­p validation náº¿u cÃ³
    if X_val_split is not None:
        val_preds = model.predict(X_val_split)
        val_r2 = r2_score(y_val_split, val_preds)
        val_rmse = np.sqrt(mean_squared_error(y_val_split, val_preds))
        val_mae = mean_absolute_error(y_val_split, val_preds)
        
        print(f"\nğŸ“Š Káº¿t quáº£ trÃªn táº­p VALIDATION:")
        print(f"RÂ² score: {val_r2:.4f}")
        print(f"RMSE: {val_rmse:.4f}")
        print(f"MAE: {val_mae:.4f}")
        
        # Kiá»ƒm tra overfitting
        print(f"\nğŸ” PhÃ¢n tÃ­ch Overfitting:")
        print(f"Gap RÂ² (train - val): {train_r2 - val_r2:.4f}")
        print(f"Gap RMSE (val - train): {val_rmse - train_rmse:.4f}")
        
        if abs(train_r2 - val_r2) > 0.1:
            print("âš ï¸ CÃ³ dáº¥u hiá»‡u overfitting (gap RÂ² > 0.1)")
        else:
            print("âœ… Model cÃ³ váº» á»•n Ä‘á»‹nh (khÃ´ng overfitting nghiÃªm trá»ng)")
    else:
        print("âš ï¸ KhÃ´ng cÃ³ táº­p validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡")
    
    # Dá»± Ä‘oÃ¡n cho táº­p test
    if len(test_data) > 0:
        X_test = test_data[feature_columns]
        # Xá»­ lÃ½ missing values trong test set
        X_test = X_test.fillna(X_train.mean())
        
        test_preds = model.predict(X_test)
        
        print(f"âœ… Dá»± Ä‘oÃ¡n hoÃ n thÃ nh cho {len(test_preds)} sinh viÃªn")
        print(f"Mean prediction: {np.mean(test_preds):.4f}")
        print(f"Std prediction: {np.std(test_preds):.4f}")
        
        # Hiá»ƒn thá»‹ feature importance
        feature_importance = pd.DataFrame({
            'feature': feature_columns,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\nTop 10 important features:")
        print(feature_importance.head(10))
        
        # Táº¡o DataFrame káº¿t quáº£ dá»± Ä‘oÃ¡n
        results_df = pd.DataFrame({
            'username': test_data['username'].values,
            'predicted_score': test_preds
        })
        
        # LÃ m trÃ²n Ä‘iá»ƒm dá»± Ä‘oÃ¡n Ä‘áº¿n 2 chá»¯ sá»‘ tháº­p phÃ¢n
        results_df['predicted_score'] = results_df['predicted_score'].round(2)
        
        # Sáº¯p xáº¿p theo username
        results_df = results_df.sort_values('username')
        
        # Xuáº¥t ra file CSV
        output_file = 'predicted_scores_CK.csv'
        results_df.to_csv(output_file, index=False, encoding='utf-8')
        
        print(f"\nâœ… ÄÃ£ xuáº¥t káº¿t quáº£ dá»± Ä‘oÃ¡n ra file: {output_file}")
        print(f"Sá»‘ sinh viÃªn Ä‘Æ°á»£c dá»± Ä‘oÃ¡n: {len(results_df)}")
        print("\nğŸ“Š Thá»‘ng kÃª káº¿t quáº£ dá»± Ä‘oÃ¡n:")
        print(f"Äiá»ƒm trung bÃ¬nh: {results_df['predicted_score'].mean():.2f}")
        print(f"Äiá»ƒm cao nháº¥t: {results_df['predicted_score'].max():.2f}")
        print(f"Äiá»ƒm tháº¥p nháº¥t: {results_df['predicted_score'].min():.2f}")
        print(f"Äá»™ lá»‡ch chuáº©n: {results_df['predicted_score'].std():.2f}")
        
        print("\nğŸ” Preview káº¿t quáº£ (10 dÃ²ng Ä‘áº§u):")
        print(results_df.head(10))
        
    else:
        print("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u test Ä‘á»ƒ dá»± Ä‘oÃ¡n")
        
except Exception as e:
    print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh training: {e}")
    import traceback
    traceback.print_exc()

