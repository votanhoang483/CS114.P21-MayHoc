# Import necessary libraries
import pandas as pd
import numpy as np

try:
    # Äá»c file
    df = pd.read_csv("./data/annonimized.csv")
    df_gt = pd.read_csv("./data/qt-public.csv")
    print("âœ… ÄÃ£ Ä‘á»c dá»¯ liá»‡u")
    
    # Kiá»ƒm tra cáº¥u trÃºc dá»¯ liá»‡u
    print(f"Shape cá»§a df: {df.shape}")
    print(f"Columns cá»§a df: {df.columns.tolist()}")
    print(f"Shape cá»§a df_gt: {df_gt.shape}")
    print(f"Columns cá»§a df_gt: {df_gt.columns.tolist()}")
    
except Exception as e:
    print(f"âŒ Lá»—i Ä‘á»c dá»¯ liá»‡u: {e}")
    exit(1)

# Preprocess data   
# Äá»•i tÃªn cá»™t
df.columns = ["assignment_id", "problem_id", "username", "is_final", "status",
                "pre_score", "coefficient", "language_id", "created_at",
                "updated_at", "judgement"]

# Xá»­ lÃ½ datetime vá»›i error handling
try:
    df["created_at"] = pd.to_datetime("2025-" + df["created_at"].astype(str), 
                                    format="%Y-%m-%d %H:%M:%S", errors='coerce')
    df["updated_at"] = pd.to_datetime("2025-" + df["updated_at"].astype(str), 
                                    format="%Y-%m-%d %H:%M:%S", errors='coerce')
except Exception as e:
    print(f"âš ï¸ Lá»—i xá»­ lÃ½ datetime: {e}")
    # Thá»­ format khÃ¡c
    df["created_at"] = pd.to_datetime(df["created_at"], errors='coerce')
    df["updated_at"] = pd.to_datetime(df["updated_at"], errors='coerce')

# Kiá»ƒm tra missing values
print("\nMissing values in each column:")
print(df.isnull().sum())

# Xá»­ lÃ½ missing values vá»›i kiá»ƒm tra kiá»ƒu dá»¯ liá»‡u
if 'pre_score' in df.columns:
    df["pre_score"] = pd.to_numeric(df["pre_score"], errors='coerce')
    df["pre_score"] = df["pre_score"].fillna(0)
    
    # Kiá»ƒm tra outliers trong pre_score
    Q1 = df["pre_score"].quantile(0.25)
    Q3 = df["pre_score"].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    print(f"\nOutliers in pre_score: {len(df[(df['pre_score'] < lower_bound) | (df['pre_score'] > upper_bound)])}")

# Chuyá»ƒn Ä‘á»•i cÃ¡c cá»™t categorical
if 'status' in df.columns:
    df["status"] = df["status"].astype("category")
if 'language_id' in df.columns:
    df["language_id"] = df["language_id"].astype("category")

print("\nData types after preprocessing:")
print(df.dtypes)

# Extract features
import json
def extract_verdicts(judgement_str):
    """
    TrÃ­ch xuáº¥t cÃ¡c loáº¡i lá»—i tá»« verdicts. Náº¿u verdicts rá»—ng => khÃ´ng cÃ³ lá»—i.
    """
    try:
        if pd.isna(judgement_str) or judgement_str is None:
            # KhÃ´ng cÃ³ verdicts â†’ khÃ´ng cÃ³ lá»—i
            return {
                'has_error': 0,
                'num_total_errors': 0,
                'num_wrong': 0,
                'num_time_limit': 0,
                'num_memory_limit': 0,
                'num_runtime_error': 0,
                'has_compile_error': 0,
                'has_other_error': 0
            }

        judgement = json.loads(str(judgement_str))
        verdicts = judgement.get('verdicts', {})
        
        # Náº¿u verdicts rá»—ng hoáº·c khÃ´ng cÃ³ lá»—i nÃ o
        if not isinstance(verdicts, dict) or len(verdicts) == 0:
            return {
                'has_error': 0,
                'num_total_errors': 0,
                'num_wrong': 0,
                'num_time_limit': 0,
                'num_memory_limit': 0,
                'num_runtime_error': 0,
                'has_compile_error': 0,
                'has_other_error': 0
            }
            
        # Khá»Ÿi táº¡o
        num_wrong = 0
        num_tle = 0
        num_mle = 0
        num_rte = 0
        has_compile_error = 0
        other_errors = 0
        
        for verdict, value in verdicts.items():
            verdict_lower = verdict.lower().strip()

            # TrÆ°á»ng há»£p Ä‘áº·c biá»‡t: key rá»—ng vÃ  value lÃ  thÃ´ng bÃ¡o lá»—i â†’ compile error
            if verdict_lower == "" and isinstance(value, str) and len(value.strip()) > 0:
                has_compile_error = 1
                continue

            # Cá»‘ gáº¯ng Ã©p sang int náº¿u cÃ³ thá»ƒ
            try:
                count = int(value)
                if count < 0: count = 0
            except:
                count = 1  # KhÃ´ng Ã©p Ä‘Æ°á»£c â†’ xem lÃ  xuáº¥t hiá»‡n Ã­t nháº¥t 1 láº§n

            if 'wrong' in verdict_lower:
                num_wrong += count
            elif 'time limit' in verdict_lower:
                num_tle += count
            elif 'memory limit' in verdict_lower:
                num_mle += count
            elif 'runtime error' in verdict_lower:
                num_rte += count
            elif 'compile' in verdict_lower:
                has_compile_error = 1
            else:
                other_errors += count

        total_errors = num_wrong + num_tle + num_mle + num_rte + has_compile_error + other_errors
        has_error = 1 if total_errors > 0 else 0

        return {
            'has_error': has_error,
            'num_total_errors': total_errors,
            'num_wrong': num_wrong,
            'num_time_limit': num_tle,
            'num_memory_limit': num_mle,
            'num_runtime_error': num_rte,
            'has_compile_error': has_compile_error,
            'has_other_error': 1 if other_errors > 0 else 0
        }

    except Exception as e:
        print(f"Lá»—i: {e}")
        return {
            'has_error': 0,
            'num_total_errors': 0,
            'num_wrong': 0,
            'num_time_limit': 0,
            'num_memory_limit': 0,
            'num_runtime_error': 0,
            'has_compile_error': 0,
            'has_other_error': 0
        }
        
        
# Ãp dá»¥ng hÃ m extract_verdicts vÃ o cá»™t judgement
if 'judgement' in df.columns:
    print("Äang xá»­ lÃ½ judgement...")
    judgement_features = df['judgement'].apply(extract_verdicts)
    
    # Chuyá»ƒn Ä‘á»•i káº¿t quáº£ thÃ nh DataFrame
    judgement_df = pd.DataFrame(judgement_features.tolist())
    
    # XÃ³a cÃ¡c cá»™t cÅ© náº¿u Ä‘Ã£ tá»“n táº¡i
    columns_to_drop = ['has_error', 'num_total_errors', 'num_wrong',
                       'num_time_limit', 'num_memory_limit', 'num_runtime_error',
                       'has_compile_error', 'has_other_error']
    df = df.drop(columns=columns_to_drop, errors='ignore')
    
    # Káº¿t há»£p vá»›i DataFrame gá»‘c
    df = pd.concat([df, judgement_df], axis=1)
    
    print("âœ… ÄÃ£ xá»­ lÃ½ xong judgement features")
    print(f"Shape sau khi thÃªm features: {df.shape}")
else:
    print("âš ï¸ KhÃ´ng tÃ¬m tháº¥y cá»™t 'judgement'")
    # Táº¡o cÃ¡c cá»™t máº·c Ä‘á»‹nh
    df['has_error'] = 0
    df['num_total_errors'] = 0
    df['num_wrong'] = 0
    df['num_time_limit'] = 0
    df['num_memory_limit'] = 0
    df['num_runtime_error'] = 0
    df['has_compile_error'] = 0
    df['has_other_error'] = 0
    
# Combine features
# Tá»•ng há»£p theo sinh viÃªn vá»›i error handling
try:
    print("Äang tá»•ng há»£p dá»¯ liá»‡u theo sinh viÃªn...")
    
    # Kiá»ƒm tra cÃ¡c cá»™t cáº§n thiáº¿t
    required_cols = ['username', 'assignment_id', 'pre_score', 'is_final']
    missing_cols = [col for col in required_cols if col not in df.columns]
    if missing_cols:
        print(f"âŒ Thiáº¿u cÃ¡c cá»™t: {missing_cols}")
        exit(1)
    
    # Tá»•ng sá»‘ bÃ i duy nháº¥t Ä‘Ã£ lÃ m
    num_assignments = df.groupby('username')['assignment_id'].nunique().rename('num_assignments')
    
    # Tá»•ng sá»‘ lÆ°á»£t ná»™p
    total_submissions = df.groupby('username').size().rename('total_submissions')
    
     # Sá»‘ bÃ i cÃ³ Ã­t nháº¥t 1 láº§n Ä‘Ãºng
    correct_df = df[df['is_final'] == 1].groupby('username')['assignment_id'].nunique().rename('num_correct')
    
    # Äiá»ƒm trung bÃ¬nh vÃ  cao nháº¥t
    score_stats = df.groupby('username')['pre_score'].agg(['mean', 'max']).rename(columns={
        'mean': 'avg_score',
        'max': 'max_score'
    })
    
    # Tá»•ng cÃ¡c loáº¡i lá»—i
    error_cols = ['num_wrong', 'num_time_limit', 'num_memory_limit', 'num_runtime_error',
                  'has_compile_error', 'has_other_error']
    error_agg = df.groupby('username')[error_cols].sum()

    # NgÃ y ná»™p Ä‘áº§u tiÃªn vÃ  cuá»‘i cÃ¹ng (náº¿u cÃ³)
    if 'created_at' in df.columns and not df['created_at'].isna().all():
        time_stats = df.groupby('username')['created_at'].agg(['min', 'max']).rename(columns={
            'min': 'first_submission',
            'max': 'last_submission'
        })
    else:
        time_stats = pd.DataFrame()

    # Gá»™p táº¥t cáº£ láº¡i
    student_features = pd.concat([
        num_assignments,
        total_submissions,
        correct_df,
        score_stats,
        error_agg,
        time_stats
    ], axis=1).fillna(0)

    # ThÃªm Ä‘áº·c trÆ°ng tá»· lá»‡ Ä‘Ãºng
    student_features['correct_ratio'] = student_features['num_correct'] / student_features['num_assignments']
    student_features['correct_ratio'] = student_features['correct_ratio'].fillna(0)

    # ThÃªm Ä‘áº·c trÆ°ng sá»‘ ngÃ y vÃ  tá»‘c Ä‘á»™ ná»™p bÃ i (náº¿u cÃ³ thá»i gian)
    if 'first_submission' in student_features.columns and 'last_submission' in student_features.columns:
        student_features['total_days'] = (student_features['last_submission'] - student_features['first_submission']).dt.days
        student_features['total_days'] = student_features['total_days'].replace(0, 1).fillna(1)
        student_features['submission_rate'] = student_features['total_submissions'] / student_features['total_days']

    # Reset index
    student_features = student_features.reset_index()

    print(f"âœ… ÄÃ£ tá»•ng há»£p xong. Shape: {student_features.shape}")

except Exception as e:
    print(f"âŒ Lá»—i khi tá»•ng há»£p: {e}")
    exit(1)

# Label ground truth
try:
    print("Äang gáº¯n nhÃ£n ground truth...")
    
    # Kiá»ƒm tra cáº¥u trÃºc df_gt
    if 'hash' not in df_gt.columns:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t 'hash' trong file ground truth")
        print(f"CÃ¡c cá»™t cÃ³ sáºµn: {df_gt.columns.tolist()}")
        exit(1)
    
    if 'diemqt' not in df_gt.columns:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y cá»™t 'diemqt' trong file ground truth")
        print(f"CÃ¡c cá»™t cÃ³ sáºµn: {df_gt.columns.tolist()}")
        exit(1)
    
    student_features = student_features.merge(df_gt, how="left", left_on="username", right_on="hash")
    
    # PhÃ¢n chia dá»¯ liá»‡u
    unknown_students = set(df["username"]) - set(df_gt["hash"])
    test_data = student_features[student_features["username"].isin(unknown_students)]
    train_data = student_features[student_features["username"].isin(df_gt["hash"])]
    
    print(f"Sá»‘ sinh viÃªn training: {len(train_data)}")
    print(f"Sá»‘ sinh viÃªn testing: {len(test_data)}")
    
    if len(train_data) == 0:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u training!")
        exit(1)
    
    # Chuáº©n bá»‹ features cho training
    feature_columns = [col for col in student_features.columns 
                      if col not in ["username", "hash", "diemqt", "first_submission", "last_submission"]]
    
    X_train = train_data[feature_columns]
    y_train = pd.to_numeric(train_data["diemqt"], errors="coerce")
    
    # Loáº¡i bá» cÃ¡c giÃ¡ trá»‹ NaN
    valid_indices = ~(y_train.isna() | X_train.isna().any(axis=1))
    X_train = X_train[valid_indices]
    y_train = y_train[valid_indices]
    
    print(f"Sá»‘ máº«u training sau khi lÃ m sáº¡ch: {len(X_train)}")
    print(f"Sá»‘ features: {len(feature_columns)}")
    print(f"Features: {feature_columns}")
    
    if len(X_train) == 0:
        print("âŒ KhÃ´ng cÃ³ dá»¯ liá»‡u training há»£p lá»‡!")
        exit(1)
    
except Exception as e:
    print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh chuáº©n bá»‹ dá»¯ liá»‡u: {e}")
    exit(1)
    
from sklearn.model_selection import train_test_split
# Chia train/validation split
try:
    print("Äang chia dá»¯ liá»‡u train/validation...")
    
    # Chia 90% train, 10% validation
    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
        X_train, y_train, 
        test_size=0.1, 
        random_state=42,
        stratify=None  # CÃ³ thá»ƒ thÃªm stratify náº¿u cáº§n
    )
    
    print(f"Táº­p training: {len(X_train_split)} samples")
    print(f"Táº­p validation: {len(X_val_split)} samples")
    
except Exception as e:
    print(f"âŒ Lá»—i khi chia dá»¯ liá»‡u: {e}")
    # Fallback: sá»­ dá»¥ng toÃ n bá»™ dá»¯ liá»‡u cho training
    X_train_split, X_val_split = X_train, None
    y_train_split, y_val_split = y_train, None
X_train_split.to_csv("./data/X_train_split.csv", index=False)

# Train model and predict
# Training model
try:
    print("Äang training model...")
    
    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

    # from sklearn.linear_model import LinearRegression

    # model = LinearRegression()
    # model.fit(X_train_split, y_train_split)
    
    # Import vÃ  train Random Forest

    # model = RandomForestRegressor(
    #     n_estimators=300,
    #     random_state=42,
    #     n_jobs=-1
    # )
    # model.fit(X_train_split, y_train_split)
    
    from lightgbm import LGBMRegressor
    model = LGBMRegressor(
        n_estimators=300, 
        learning_rate=0.01, 
        random_state=42,
        verbose=-1,  # Táº¯t log
        early_stopping_rounds=50 if X_val_split is not None else None
    )
    # Fit vá»›i validation set náº¿u cÃ³
    if X_val_split is not None:
        model.fit(
            X_train_split, y_train_split,
            eval_set=[(X_val_split, y_val_split)],
            eval_metric='rmse',
        )
    else:
        model.fit(X_train_split, y_train_split)
        
    print("âœ… Training hoÃ n thÃ nh")
        
# ÄÃ¡nh giÃ¡ trÃªn táº­p training
    train_preds = model.predict(X_train_split)
    train_r2 = r2_score(y_train_split, train_preds)
    train_rmse = np.sqrt(mean_squared_error(y_train_split, train_preds))
    train_mae = mean_absolute_error(y_train_split, train_preds)
    
    print(f"\nğŸ“Š Káº¿t quáº£ trÃªn táº­p TRAINING:")
    print(f"RÂ² score: {train_r2:.4f}")
    print(f"RMSE: {train_rmse:.4f}")
    print(f"MAE: {train_mae:.4f}")
    
    # ÄÃ¡nh giÃ¡ trÃªn táº­p validation náº¿u cÃ³
    if X_val_split is not None:
        val_preds = model.predict(X_val_split)
        val_r2 = r2_score(y_val_split, val_preds)
        val_rmse = np.sqrt(mean_squared_error(y_val_split, val_preds))
        val_mae = mean_absolute_error(y_val_split, val_preds)
        
        print(f"\nğŸ“Š Káº¿t quáº£ trÃªn táº­p VALIDATION:")
        print(f"RÂ² score: {val_r2:.4f}")
        print(f"RMSE: {val_rmse:.4f}")
        print(f"MAE: {val_mae:.4f}")
        
        # Kiá»ƒm tra overfitting
        print(f"\nğŸ” PhÃ¢n tÃ­ch Overfitting:")
        print(f"Gap RÂ² (train - val): {train_r2 - val_r2:.4f}")
        print(f"Gap RMSE (val - train): {val_rmse - train_rmse:.4f}")
        
        if abs(train_r2 - val_r2) > 0.1:
            print("âš ï¸ CÃ³ dáº¥u hiá»‡u overfitting (gap RÂ² > 0.1)")
        else:
            print("âœ… Model cÃ³ váº» á»•n Ä‘á»‹nh (khÃ´ng overfitting nghiÃªm trá»ng)")
    else:
        print("âš ï¸ KhÃ´ng cÃ³ táº­p validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡")
    
    # Dá»± Ä‘oÃ¡n cho táº­p test
    if len(test_data) > 0:
        X_test = test_data[feature_columns]
        # Xá»­ lÃ½ missing values trong test set
        X_test = X_test.fillna(X_train.mean())
        
        test_preds = model.predict(X_test)
        
        print(f"âœ… Dá»± Ä‘oÃ¡n hoÃ n thÃ nh cho {len(test_preds)} sinh viÃªn")
        print(f"Mean prediction: {np.mean(test_preds):.4f}")
        print(f"Std prediction: {np.std(test_preds):.4f}")
        
        # Hiá»ƒn thá»‹ feature importance
        feature_importance = pd.DataFrame({
            'feature': feature_columns,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\nTop 10 important features:")
        print(feature_importance.head(10))
        
        # Táº¡o DataFrame káº¿t quáº£ dá»± Ä‘oÃ¡n
        results_df = pd.DataFrame({
            'username': test_data['username'].values,
            'predicted_score': test_preds
        })
        
        # LÃ m trÃ²n Ä‘iá»ƒm dá»± Ä‘oÃ¡n Ä‘áº¿n 2 chá»¯ sá»‘ tháº­p phÃ¢n
        results_df['predicted_score'] = results_df['predicted_score'].round(2)
        
        # Sáº¯p xáº¿p theo username
        results_df = results_df.sort_values('username')
        
        # Xuáº¥t ra file CSV
        output_file = 'predicted_scores_QT.csv'
        results_df.to_csv(output_file, index=False, encoding='utf-8')
        
        print(f"\nâœ… ÄÃ£ xuáº¥t káº¿t quáº£ dá»± Ä‘oÃ¡n ra file: {output_file}")
        print(f"Sá»‘ sinh viÃªn Ä‘Æ°á»£c dá»± Ä‘oÃ¡n: {len(results_df)}")
        print("\nğŸ“Š Thá»‘ng kÃª káº¿t quáº£ dá»± Ä‘oÃ¡n:")
        print(f"Äiá»ƒm trung bÃ¬nh: {results_df['predicted_score'].mean():.2f}")
        print(f"Äiá»ƒm cao nháº¥t: {results_df['predicted_score'].max():.2f}")
        print(f"Äiá»ƒm tháº¥p nháº¥t: {results_df['predicted_score'].min():.2f}")
        print(f"Äá»™ lá»‡ch chuáº©n: {results_df['predicted_score'].std():.2f}")
        
        print("\nğŸ” Preview káº¿t quáº£ (10 dÃ²ng Ä‘áº§u):")
        print(results_df.head(10))
        
    else:
        print("âš ï¸ KhÃ´ng cÃ³ dá»¯ liá»‡u test Ä‘á»ƒ dá»± Ä‘oÃ¡n")
        
except Exception as e:
    print(f"âŒ Lá»—i trong quÃ¡ trÃ¬nh training: {e}")
    import traceback
    traceback.print_exc()

